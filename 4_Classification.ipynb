{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True\n",
    "%matplotlib inline\n",
    "\n",
    "#train_set, val_set = torch.utils.data.random_split(dataset, [50000, 10000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of transformations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))]) #((mean*n_c), (std*n_c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = torchvision.datasets.CIFAR10(root='./data', train = True, download = True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = 4, shuffle = True, num_workers = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = torchvision.datasets.CIFAR10(root='./data', train = False, download = False, transform = transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size = 4, shuffle = True, num_workers = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('plane', 'car', 'bird', 'cat','deer', \n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imgshow(img):\n",
    "    img = (img/2)+0.5\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(trainloader)\n",
    "img, label = dataiter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 32])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(16*5*5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool1(F.relu(self.conv2(x)))\n",
    "        \n",
    "        x = x.view(-1, 16*5*5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "net = Net()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr = 0.001, momentum = .9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _DataLoaderIter.__del__ at 0x7f348b6bb620>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aditya/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 677, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/aditya/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 659, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/aditya/anaconda3/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0, 0 - Loss: 0.0011482141017913818\n",
      "0, 2000 - Loss: 1.8415190180540084\n",
      "0, 4000 - Loss: 1.7689051042497157\n",
      "0, 6000 - Loss: 1.7207437451779843\n",
      "0, 8000 - Loss: 1.7079410113692284\n",
      "0, 10000 - Loss: 1.7022317141294478\n",
      "0, 12000 - Loss: 1.677804727077484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _DataLoaderIter.__del__ at 0x7f348b6bb620>\n",
      "    self._shutdown_workers()\n",
      "Traceback (most recent call last):\n",
      "Exception ignored in: <function _DataLoaderIter.__del__ at 0x7f348b6bb620>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aditya/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 677, in __del__\n",
      "  File \"/home/aditya/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 677, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/aditya/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 659, in _shutdown_workers\n",
      "  File \"/home/aditya/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 659, in _shutdown_workers\n",
      "    w.join()\n",
      "    w.join()\n",
      "  File \"/home/aditya/anaconda3/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "  File \"/home/aditya/anaconda3/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "AssertionError: can only join a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1, 0 - Loss: 0.0008496413230895996\n",
      "1, 2000 - Loss: 1.6384752558469773\n",
      "1, 4000 - Loss: 1.642255889505148\n",
      "1, 6000 - Loss: 1.6363129316717386\n",
      "1, 8000 - Loss: 1.6121260406970979\n",
      "1, 10000 - Loss: 1.5869621372520923\n",
      "1, 12000 - Loss: 1.575574921220541\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2):\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        \n",
    "        inputs, label = data\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        out = net(inputs)\n",
    "        loss = criterion(out, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if i%2000 == 0:\n",
    "            print(f'{epoch}, {i} - Loss: {running_loss/2000}')\n",
    "            running_loss = 0\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './cifar_net.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
